{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010, 150)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('responses.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010, 7) float64\n"
     ]
    }
   ],
   "source": [
    "X = df.as_matrix()\n",
    "X = X[:,133:140]\n",
    "X = X.astype(float)\n",
    "print(X.shape,X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "labels = df.Education.as_matrix()\n",
    "print(labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994, 7) (994,)\n"
     ]
    }
   ],
   "source": [
    "#Delete rows that have empty cells\n",
    "empty = np.zeros(1010,dtype=bool)\n",
    "for i in range(1010):\n",
    "    for j in range(7):\n",
    "        if np.isnan(X[i][j]):\n",
    "            empty[i] = True\n",
    "empty[831] = True #831 does not have education level. \n",
    "X = X[~empty]\n",
    "labels = labels[~empty]\n",
    "print(X.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.zeros(994)\n",
    "for i in range(994):\n",
    "    if labels[i] == \"currently a primary school pupil\":\n",
    "        label[i] = 0\n",
    "    if labels[i] == \"primary school\":\n",
    "        label[i] = 1\n",
    "    if labels[i] == \"secondary school\":\n",
    "        label[i] = 2\n",
    "    if labels[i] == \"college/bachelor degree\":\n",
    "        label[i] = 3\n",
    "    if labels[i] == \"masters degree\":\n",
    "        label[i] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training, validation, and testing set. \n",
    "train_spending = X[:800]\n",
    "train_labels = label[:800]\n",
    "validation_spending = X[800:900]\n",
    "validation_labels = label[800:900]\n",
    "test_spending = X[900:]\n",
    "test_labels = label[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size):\n",
    "    # model.train() puts our model in train mode, which can require different\n",
    "    # behavior than eval mode (for example in the case of dropout).\n",
    "    model.train()\n",
    "    # i is is a 1-D array with shape [batch_size]\n",
    "    i = np.random.choice(train_spending.shape[0], size=batch_size, replace=False)\n",
    "    x = autograd.Variable(torch.from_numpy(train_spending[i].astype(np.float32)))\n",
    "    y = autograd.Variable(torch.from_numpy(train_labels[i].astype(np.int)))\n",
    "    optimizer.zero_grad()\n",
    "    y_hat_ = model(x)\n",
    "    loss = F.cross_entropy(y_hat_, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an accuracy function\n",
    "def accuracy(y, y_hat):\n",
    "   \"\"\"Compute accuracy.\n",
    "   Args:\n",
    "       y: A 1-D int NumPy array.\n",
    "       y_hat: A 1-D int NumPy array.\n",
    "   Returns:\n",
    "       A float, the fraction of time y[i] == y_hat[i].\n",
    "   \"\"\"\n",
    "   return (y == y_hat).astype(np.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_train_accuracy():\n",
    "    model.train()\n",
    "    index = list(range(800))\n",
    "    random.shuffle(index)\n",
    "    index = index[:100]\n",
    "    \n",
    "    X = train_spending[index]\n",
    "    y = train_labels[index]\n",
    "    y_raw = torch.from_numpy(np.zeros((100,5)))\n",
    "    \n",
    "    for i in range(100):\n",
    "        X_ = Variable(torch.from_numpy(X[i]).type(torch.FloatTensor))\n",
    "        y_raw[i] = model(X_).data\n",
    "        \n",
    "    _,y_pred = torch.max(y_raw,1)\n",
    "    return accuracy(y,y_pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_accuracy():\n",
    "    model.eval()\n",
    "    y_raw = torch.from_numpy(np.zeros((100,5)))\n",
    "    for i in range(100):\n",
    "        X_ = Variable(torch.from_numpy(validation_spending[i]).type(torch.FloatTensor))\n",
    "        y_raw[i] = model(X_).data\n",
    "    _,y_pred = torch.max(y_raw,1)\n",
    "    return accuracy(validation_labels,y_pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(7, 20)\n",
    "        self.linear2 = torch.nn.Linear(20,10)\n",
    "        self.linear3 = torch.nn.Linear(10,5)\n",
    "    def forward(self,x):\n",
    "        x = self.linear3(F.sigmoid(self.linear2(F.sigmoid(self.linear1(x)))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  0.04  0.03\n",
      "    50  0.56  0.65\n",
      "   100  0.61  0.65\n",
      "   150  0.62  0.65\n",
      "   200  0.62  0.65\n",
      "   250  0.57  0.65\n",
      "   300  0.55  0.65\n",
      "   350  0.60  0.65\n",
      "   400  0.60  0.65\n",
      "   450  0.54  0.65\n",
      "   500  0.64  0.65\n",
      "   550  0.55  0.65\n",
      "   600  0.63  0.65\n",
      "   650  0.52  0.65\n",
      "   700  0.66  0.65\n",
      "   750  0.66  0.65\n",
      "   800  0.54  0.65\n",
      "   850  0.66  0.65\n",
      "   900  0.62  0.65\n",
      "   950  0.62  0.65\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = TwoLayerNN()\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "train_accs, val_accs = [], []\n",
    "index = []\n",
    "for i in range(1000):\n",
    "    train(50)\n",
    "    if i % 50 == 0:\n",
    "        train_accs.append(approx_train_accuracy())\n",
    "        val_accs.append(val_accuracy())\n",
    "        index.append(i)\n",
    "        print(\"%6d %5.2f %5.2f\" % (i, train_accs[-1], val_accs[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5,whiten=True)\n",
    "b = pca.fit_transform(train_spending)\n",
    "v = pca.fit_transform(validation_spending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# K nearest neighbor\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(25)\n",
    "y_pred = clf.fit(b,train_labels).predict(v)\n",
    "\n",
    "print(accuracy(validation_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.61676713293 0.00573236791368 0.61\n",
      "2 0.61676713293 0.00573236791368 0.61\n",
      "3 0.611695388769 0.00612547770898 0.6\n",
      "4 0.601653978505 0.0136160189526 0.565656565657\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for depth in range(1,5):\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    s = cross_val_score(clf, X,label, cv=10) # apples to apples?\n",
    "    print (depth, s.mean(), s.std(), s.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61386139,  0.61386139,  0.61386139,  0.61      ,  0.61      ,\n",
       "        0.61616162,  0.61616162,  0.62244898,  0.62244898,  0.62886598])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10,max_depth=3)\n",
    "cross_val_score(clf, X,label, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "y_pred = gnb.fit(train_spending, train_labels).predict(validation_spending)\n",
    "\n",
    "print(accuracy(validation_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_spending,train_labels)\n",
    "y_pred = clf.predict(validation_spending)\n",
    "\n",
    "print(accuracy(validation_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear') #Sigmoid also gives the same accuracy\n",
    "clf.fit(train_spending,train_labels)\n",
    "y_pred = clf.predict(validation_spending)\n",
    "\n",
    "print(accuracy(validation_labels,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
